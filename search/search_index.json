{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What?","text":""},{"location":"#what-is-scalable-modeling","title":"What is Scalable Modeling?","text":""},{"location":"#the-problem-when-growth-becomes-your-enemy","title":"The Problem: When Growth Becomes Your Enemy","text":"<p>Most software systems start small and simple. A single server, a straightforward database, perhaps a monolithic application that handles everything. This works beautifully until it doesn't. As user demand grows, what once was your advantage (rapid development, simple deployment) becomes your constraint. Database queries slow down, servers crash under load, and making changes feels like performing surgery on a patient that can't be anesthetized.</p> <p>The traditional response? \"We'll scale when we need to.\" But by then, you're redesigning fundamental architecture under pressure, with users waiting and revenue at stake. It's like trying to widen a highway during rush hour.</p>"},{"location":"#the-solution-design-patterns-that-scale-naturally","title":"The Solution: Design Patterns That Scale Naturally","text":"<p>Justification for the red arrows in sections: Queries &amp; Time Travel.</p> <p>Scalable Modeling is a design methodology that uses patterns and structures that naturally support growth. You can start with the simplest possible implementation and evolve it incrementally as needs arise.</p> <p>Think of it like choosing the right building materials. You might start with a small structure, but by using materials and techniques that support expansion, you can grow organically without rebuilding from scratch. The key is making choices that keep your options open.</p>"},{"location":"#core-approach-event-centric-architecture","title":"Core Approach: Event-Centric Architecture","text":"<p>The Scalable Modeling methodology combines two complementary approaches:</p> <p>Scalable Modeling focuses on understanding and designing systems by drawing from:</p> <ul> <li>Domain-Driven Design (DDD) for business alignment and domain modeling</li> <li>EventStorming for collaborative modeling and discovery</li> </ul> <p>CEQS (Command-Event-Query Separation) focuses on architectural implementation by drawing from:</p> <ul> <li>Clean Architecture for separation of concerns</li> <li>Event-Driven Architecture (EDA) for loose coupling</li> <li>CQRS for read/write optimization</li> </ul> <p>Rather than rigidly following any single approach, this methodology synthesizes modeling and architectural concepts into a flexible system that adapts to your specific needs.</p>"},{"location":"#the-foundation-opportunities-and-challenges","title":"The Foundation: Opportunities and Challenges","text":"<p>Scalable Modeling recognizes that scalability involves both opportunities to leverage and challenges to overcome:</p>"},{"location":"#three-opportunities-for-scale","title":"Three Opportunities for Scale","text":"<ol> <li>Decomposition - Scale by splitting different things (services, domains, responsibilities)</li> <li>Duplication - Scale by cloning (horizontal scaling, redundancy)</li> <li>Partition - Scale by splitting similar things (data sharding, load distribution)</li> </ol>"},{"location":"#three-challenges-to-address","title":"Three Challenges to Address","text":"<ol> <li>Deduplication - Managing duplicate messages since exactly-once delivery is impossible in distributed systems</li> <li>Tailoring Consistency - Choosing appropriate consistency models beyond \"strong by default\"</li> <li>Time Travel - Handling eventual consistency across distributed components</li> </ol> <p>The key insight: immutability of messages and events plays a crucial role in leveraging each opportunity while mitigating each challenge.</p>"},{"location":"#the-building-blocks","title":"The Building Blocks","text":"<p>Scalable Modeling provides specific components for modeling scalable systems:</p> <ul> <li>Events - Immutable records that enable distribution and scalability (both private and public)</li> <li>Commands and State - Validated operations that modify state according to business rules</li> <li>Queries - Read operations typically separated from command models</li> <li>Policies - Rules that glue parts together</li> <li>Bounded Contexts - Clear boundaries around domain areas with specific language and rules</li> <li>Ubiquitous Language - Shared vocabulary between all stakeholders</li> <li>Consistency Boundaries - Enable tailoring consistency</li> </ul> <p>These components work together to create systems where each piece has a clear purpose and can evolve independently.</p>"},{"location":"#the-bridge-from-why-to-how","title":"The Bridge: From Why to How","text":"<p>Software engineering involves three critical phases:</p> <ul> <li>Understanding (WHY): What problem are we solving and for whom?</li> <li>Designing (WHAT): What is our conceptual model for the solution?</li> <li>Developing (HOW): How do we implement this solution?</li> </ul> <p> </p> <p>Scalable Modeling serves as an opinionated bridge from WHY to HOW, with primary focus on the WHAT. By investing in conceptual modeling before implementation, you iterate faster and cheaper. Changing a diagram is typically orders of magnitude easier than refactoring production code. CEQS provides guardrails for the HOW, ensuring your implementation choices support scalability.</p>"},{"location":"#your-journey-ahead","title":"Your Journey Ahead","text":"<p>This methodology isn't about upfront complexity or building features you don't need yet. It's about choosing patterns and structures that naturally accommodate growth. You can start with a simple implementation and evolve it incrementally as your requirements change.</p> <p>Whether you're starting a new project or looking to refactor an existing system, Scalable Modeling provides the conceptual tools to make evolution easier. When your system needs to handle more load or complexity, you'll have an architecture that can adapt rather than one that must be rebuilt.</p> <p>Whether you're starting a new project or looking to refactor an existing system, Scalable Modeling provides the conceptual tools to design for growth. The following sections will guide you through the practical application of these principles, helping you build systems where growth becomes an advantage rather than an obstacle.</p>"},{"location":"#license-for-using-the-pictures","title":"License For Using the Pictures","text":"<p>See License.</p>"},{"location":"ceqs/","title":"CEQS","text":""},{"location":"ceqs/#ceqs","title":"CEQS","text":"<p>Command-Event-Query Separation highlights the crucial role events play in building scalable systems.</p>"},{"location":"ceqs/#event-centric-approach","title":"Event-centric Approach","text":"<p>The diagram below illustrates a novel software architecture concept called CEQS \u2014 Command-Event-Query Separation. It is an enhancement of the traditional CQS (Command Query Separation) pattern highlighting the importance of events in scalable systems.</p> <p> </p> <p>In scalable systems, events should be treated as first-class citizens, as their immutability is fundamental to achieving  scalability. Their asynchronous nature enables loose coupling between services, while their immutability allows events  to be queried or streamed as an accurate record of what has occurred within the system.</p> <p>Immutability ensures that events are append-only, enabling distributed systems to replicate and process data  consistently across services without conflicts. Immutable streams of private events allow new query models to be  projected at any point in a system's lifespan. In CEQS, model separation (command vs. query) is not strictly enforced  from day one. When increased complexity, scalability, or usability demands arise, query models can be introduced as  needed. This flexibility means that, unlike in CQRS, in CEQS model separation is not always necessary upfront.</p> <p>Commands, Events and Queries each serve as distinct interfaces to a service:</p> <ul> <li>Commands initiate state changes, resulting in the creation of Events.</li> <li>Events represent the immutable outcomes of those state changes, facilitating asynchronous communication and    providing a historical log.</li> <li>Queries retrieve current or historical data without causing side effects.</li> </ul> <p>This clear separation of concerns ensures that systems remain scalable, decoupled, and maintainable.</p> <p>CEQS also further separate events into two categories:</p> <ul> <li> <p>Private events   Internal to a service and persisted for internal logic and consistency.</p> </li> <li> <p>Public events   Exposed to other services to represent meaningful business changes and enable communication.</p> </li> </ul> <p>This structure helps manage boundaries between internal behavior and external integration.</p>"},{"location":"ceqs/#architectural-benefits","title":"Architectural Benefits","text":"<ol> <li>Clean Domain Logic<ul> <li>Separating commands and queries results in clearer, more focused domain logic. Commands handle state changes,   while queries handle data retrieval, ensuring that business logic remains concise and purpose-driven.</li> </ul> </li> <li>Separation of Concerns<ul> <li>Commands are responsible for writing data (changing state), while queries are responsible for reading data. This   distinction enhances maintainability by providing cleaner code and reducing the risk of unintended side effects.</li> </ul> </li> <li>Loose Coupling<ul> <li>Within Services: Commands and queries are decoupled through immutable, private events, allowing each to evolve   independently without interference.</li> <li>Between Services: Public events decouple microservices, enabling them to operate and scale independently,   reducing dependencies between service boundaries.</li> </ul> </li> <li>Resiliency<ul> <li>The system is more resilient because failures in one component (e.g. command processing) do not cascade to others   (e.g. queries). This design ensures fault isolation and minimizes downtime.</li> </ul> </li> <li>Near-Real-Time Integrations<ul> <li>Events enable near-real-time communication between services, allowing for fast and seamless integration. This   improves responsiveness to changes in the system and facilitates use cases like live updates.</li> </ul> </li> <li>Low Latency at Any Scale<ul> <li>By separating read and write responsibilities, the system can optimize availability and scalability. For example:<ul> <li>High Availability: Read-heavy workloads can be handled by scaling replicas.</li> <li>Scalability: This architecture supports all three dimensions to scalability, ensuring low latency even under high demand.</li> </ul> </li> </ul> </li> </ol>"},{"location":"ceqs/#summary","title":"Summary","text":"<ol> <li> <p>Events as First-Class Citizens    Events are treated as equal partners alongside commands and queries.    They are core domain concepts, not just integration artifacts.</p> </li> <li> <p>Explicit Separation of Concerns    CEQS introduces events as a third architectural concern in addition to commands and queries, providing clearer boundaries and more flexible composition.</p> </li> <li> <p>Temporal-First Design    Focuses on modeling sequences of events before considering current state or structure.    Builds on the temporal thinking from Scalable Modeling.</p> </li> <li> <p>Flexible Consistency Boundaries    Different parts of the system can adopt different consistency models, guided by domain needs instead of technical constraints.</p> </li> </ol>"},{"location":"ceqs/#questions-answers","title":"Questions &amp; Answers","text":""},{"location":"ceqs/#1-what-makes-ceqs-different-from-traditional-cqrs","title":"1. What makes CEQS different from traditional CQRS?","text":"<p>Unlike in CQRS:</p> <ul> <li> <p>Events are first-class citizens   Events are treated as core domain concepts, not just side effects or integration tools. They are on equal footing with commands and queries.</p> </li> <li> <p>Gradual query model evolution   The query model is structurally the same as the command model but without command handlers (i.e. business validation). This allows teams to start with a unified model and separate it only when needed.   For example, you might start with a <code>User</code> aggregate used in both commands and queries. Later, if your query load grows or you need specialized views (e.g. user lists), you can evolve the query model independently, by projecting events to form a separate model.</p> </li> <li> <p>More focus on evolvability   Events help systems adapt and grow over time without requiring major rewrites or early rigid structures.</p> </li> </ul>"},{"location":"ceqs/#2-what-role-do-hotspots-descriptions-and-policies-play-in-ceqs","title":"2. What role do Hotspots, Descriptions and Policies play in CEQS?","text":"<p>These are supporting concepts and tools used alongside CEQS but are not part of its core architecture:</p> <ul> <li> <p>Hotspots, descriptions and ubiquitous language   These come from EventStorming and support domain modeling and understanding. They help design better systems but are not unique to CEQS.</p> </li> <li> <p>Policies   Implemented using subscribers and publishers.   For example, a subscriber might listen to \"warehouse item low\" and trigger the command \"order more\".   This is a policy expressed as a simple reactive connection between an event and a command.   Not all subscribers and publishers need complex logic though.</p> </li> </ul>"},{"location":"challenges/","title":"Challenges","text":""},{"location":"challenges/#challenges","title":"Challenges","text":"<p>When modeling scalable systems, you need to understand the following three challenges. They relate to distribution and scalability. Even if your implementation is not yet distributed and maintains strong consistency, it is important to anticipate these challenges in advance. Consider how the system could evolve to address them when the need arises.</p>"},{"location":"challenges/#deduplication","title":"Deduplication","text":"<p>Since exactly-once delivery is impossible in distributed systems, we use effectively-once or idempotent processing to  ensure duplicate messages don\u2019t affect the outcome.</p>"},{"location":"challenges/#tailoring-consistency","title":"Tailoring Consistency","text":"<p>Quote</p> <p>\"Developers simply do not implement large scalable applications assuming distributed transactions... Two-phase commit is the anti-availability protocol.\"</p> <p>Pat Helland</p> <p>In distributed systems, defining consistency boundaries is crucial for balancing performance and correctness. These boundaries determine where strong consistency is enforced and where eventual consistency is acceptable. Interestingly, tailoring these boundaries often requires business-driven decisions. For instance, while financial transactions demand strict consistency, less critical processes like reporting can tolerate delays.</p> <p>By explicitly defining consistency boundaries, you ensure the system aligns with business needs while optimizing scalability. This approach prevents over-engineering and allows the system to scale efficiently without unnecessary constraints.</p> <p> </p> <p>In the context of scalability, distribution and consistency, it is also worth mentioning conflict-free replicated data  types (CRDTs). CRDTs enable concurrent updates by multiple nodes without requiring centralized conflict resolution.  This reduces the need for managing atomic operations in distributed systems. By leveraging CRDTs, consistency can be  tailored to prioritize availability and eventual alignment, making them an effective choice for scenarios where  strict consistency boundaries are not critical.</p>"},{"location":"challenges/#time-travel","title":"Time Travel","text":"<p>When using CQRS with eventually consistent read models, the system's read models may reflect different points in  time due to the delay in propagating updates. This allows for a form of \"time travel,\" where users can observe data at  various stages of consistency. As new events are processed, the read model gradually \"catches up\" with the latest state.  However, during this period, the system might expose outdated or future-looking states, effectively letting users or  systems \"travel\" between these states.</p> <p>This is particularly significant when querying or presenting data that spans multiple sources or services across  consistency boundaries. For example, one source might reflect an older version of the data, while another presents the  most recent state.</p> <p>As a result, combining data from these sources may yield conflicting or incoherent views of the overall system. This  inconsistency poses a challenge when trying to form a unified or accurate perspective of the current state. To mitigate  these issues, designers need to carefully consider the timing and aggregation of data to avoid misleading or  inconsistent results, especially in cases where decisions are being made based on these read models.</p> <p>Avoiding Loops to Prevent Time Travel</p> <p>One common source of time travel issues in distributed systems is the presence of loops in the architecture. Feedback loops between services can introduce subtle timing problems, cause race conditions and lead to eventual consistency violations. These loops make it difficult to reason about the state of the system at any given point and often result in unexpected behavior.</p> <p>Loops can cause components to observe partial or out-of-date information or even see future state due to out-of-order event delivery. This breaks the mental model of cause and effect and undermines the reliability of event-driven workflows.</p> <p>In general, it's best to design systems using simple acyclic data flows. Unidirectional flows are easier to understand, test and scale. If a feedback mechanism is absolutely necessary, it should be isolated, tightly controlled and made idempotent to avoid cascading inconsistencies.</p> <p>Example: Cross-Entity Uniqueness</p> <p>A typical example of a loop arises when implementing cross-entity uniqueness constraints. For instance, a user might have a unique user ID but also an email address that must be globally unique. Enforcing email uniqueness can easily introduce a loop:</p> <ul> <li>The email registry needs to know which user currently owns the address</li> <li>The user entity may need confirmation that the email is available</li> <li>Race conditions occur if two users try to claim the same address at the same time</li> </ul> <p>To handle this safely, you need a clear protocol to reserve, update and release the email address. This should be done through a dedicated coordination service or component that serializes access to the shared constraint, avoiding circular dependencies between user entities.</p> <p>Avoiding loops is one of the simplest and most effective ways to reduce complexity and improve consistency in scalable systems.</p>"},{"location":"components/","title":"Components","text":""},{"location":"components/#components","title":"Components","text":"<p>Scalable Modeling uses the following components to model scalable systems.</p> <ul> <li>Components</li> <li>Bounded Contexts</li> <li>Events</li> <li>Ubiquitous Language</li> <li>Commands and State</li> <li>Queries</li> <li>Policies</li> <li>Hotspots and Descriptions</li> <li>Consistency Boundaries</li> </ul>"},{"location":"components/#bounded-contexts","title":"Bounded Contexts","text":"<p>Bounded context can be thought as one service in a larger system. It defines a clear boundary around a specific part  of the domain where particular terms, rules, and models are valid. It helps avoid ambiguity by isolating concepts and  ensuring they only apply within that boundary. Think of it as a focused \"space\" where a specific  language and logic make sense, independent of others.</p>"},{"location":"components/#events","title":"Events","text":"<p>Events are immutable, enabling duplication which helps in distribution and scalability. - Private Events are specific to the bounded context. - Public Events are shared externally.</p> <p> </p>"},{"location":"components/#ubiquitous-language","title":"Ubiquitous Language","text":"<p>Ubiquitous language is more than connections and stickies in the picture above. At best, it is a shared conceptual  framework that allows both technical and non-technical stakeholders to collaborate effectively, ensuring that all  parties have a common understanding of the domain and its logic. It helps avoid ambiguity, enabling precise  communication and design decisions, fostering a deep connection between the code and the business model it represents.</p> <p>This language allows everyone involved to speak the same language, preventing misunderstandings and ensuring that the  system's design remains consistent with the business goals and domain requirements.</p>"},{"location":"components/#commands-and-state","title":"Commands and State","text":"<p>Commands are validated against a model that frames the state. The model defines the logic, rules and structure of the state, which is persisted through events or direct updates. Commands modify the state by adhering to the rules defined by the model, ensuring business invariants are maintained.</p>"},{"location":"components/#queries","title":"Queries","text":"<p>Querying the Command Model (illustrated by the red arrow in the picture above) is a topic that often generates  strong opinions. In essence, the command model is a specialized type of model designed to validate commands. While it  is not intended for querying, there are certain scenarios where reading from it may be justified.</p> <p>For example, in in-memory command models (such as Akka-style), where the model is clustered,  a valid use case might involve querying the state of an entity immediately after its creation or update. Since the  entity resides in memory, fetching its state quickly can be reasonable and efficient.</p> <p>Additionally, immutable streams of private events allow for the projection of new query models at any point in a  system's lifecycle. This enables model separation to be implemented on-demand, as needed.</p> <p>That said, querying the command model can easily lead to misuse, such as performance bottlenecks or data  inconsistencies. Therefore, as a general rule, it's best to maintain model separation and use the command model for  queries only when there is a clear, well-justified benefit.</p>"},{"location":"components/#policies","title":"Policies","text":"Component Purpose Key Responsibility Sync/Async Consistency Level Gatekeeper Validates commands before dispatch Enforces business rules with best available state across consistency boundaries Sync Best effort, may be stale Command Handler Executes commands against models Applies state changes safely within consistency boundaries Sync Strong, authoritative Event Handler Reacts to domain events asynchronously Updates models, triggers workflows, reconciles Async Eventual Query Handler Serves read requests efficiently Provides data from a single, read-optimized view Sync Eventually consistent Data Processor Maintains derived or aggregated models Combines multiple sources into query-friendly views Sync Eventually consistent"},{"location":"components/#gatekeeper","title":"Gatekeeper","text":"<p>Context</p> <p>Distributed systems inevitably span multiple nodes, regions or even continents. Because of this distribution, communication across components is never instantaneous. It is bounded by network latency and the speed of light.</p> <p>The consequence is eventual consistency: state observed in one part of the system may lag behind state in another. When commands are received, they often require validation that involves fetching data across these consistency boundaries. This means the Gatekeeper may consult stale or incomplete models during validation.</p> <p>Problem</p> <p>How can we validate and execute commands safely in an environment where the data required for validation may not be fully up-to-date?</p> <p>Forces</p> Force Description Physics Network latency and the speed of light make instantaneous global coordination impossible Eventual consistency Both commands and validation queries may see stale or partial data Integrity Business rules must still hold (for example orders cannot reference missing products) Responsiveness Over-synchronization increases latency and hurts availability Practicality Global transactions are too costly and fragile at scale <p>Solution</p> <p>Introduce a Gatekeeper that intercepts commands before dispatch. The Gatekeeper validates preconditions by consulting models. It acknowledges that data may be stale, so it enforces logical rules based on the best available view.</p> <p>If checks fail, the command is rejected. If checks succeed, the command is passed on to the Command Handler for execution. For cases where distribution causes timing conflicts, combine the Gatekeeper with Event Handlers that reconcile state over time.</p> <p>Implementation</p> <ul> <li>Place the Gatekeeper between incoming Command and the Command Handler</li> <li>Use models to validate logical preconditions</li> <li>Keep Gatekeepers lightweight and avoid introducing side effects</li> <li>Reject or forward commands based on validation outcome</li> <li>Pair with Event Handlers for long-term consistency guarantees</li> </ul> <p>Example</p> <ul> <li>A customer places an order: the Gatekeeper verifies that the referenced product exists in the product model</li> <li>A product is about to be archived: the Gatekeeper checks the order model to see if open orders still reference it</li> <li>Race condition: A customer places an order for a product at the exact same moment that the product is being archived<ul> <li>The Gatekeeper may validate against stale state and approve the order</li> <li>This race condition cannot be fully avoided due to distribution and asynchronous propagation</li> <li>Such conflicts are caught later by Event Handlers, which reconcile the system state (for example canceling the invalid order or compensating the customer)</li> </ul> </li> </ul> <p>Resulting Context</p> <ul> <li>The system remains available and fast because global synchronization is avoided</li> <li>Logical safety nets prevent most invalid commands from corrupting state</li> <li>Remaining inconsistencies are delegated to asynchronous reconciliation</li> </ul> <p>Consequences</p> Type Description \u2705 Prevents many invalid operations at command boundaries \u2705 Keeps write-side execution simple by moving validation out \u26a0\ufe0f Dependent on model freshness, stale data can cause false negatives or positives <p>Related Patterns</p> <ul> <li>Event Handler: Ensures eventual reconciliation of state inconsistencies</li> <li>Command Handler: Executes commands only after Gatekeeper approval</li> </ul>"},{"location":"components/#command-handler","title":"Command Handler","text":"<p>Context</p> <p>Every distributed system must change state in response to incoming requests. These requests, modeled as commands, represent intent to perform an action (for example PlaceOrder).</p> <p>Within a single consistency boundary, state changes can be validated and applied synchronously. Distribution does not eliminate the need for authoritative state, it just means that such validation is localized to where the model lives.</p> <p>Problem</p> <p>How can we process commands safely against a mutable model, ensuring correctness in the presence of concurrent modifications?</p> <p>Forces</p> Force Description Concurrency Multiple commands may target the same state simultaneously Integrity Domain invariants must hold (for example inventory cannot go negative) Performance Users expect responsive command execution Isolation We want to validate against authoritative state without requiring consensus <p>Solution</p> <p>A Command Handler is responsible for executing a command against an authoritative model. It validates the command synchronously against that model and applies state changes if valid.</p> <p>Concurrency is handled using optimistic concurrency control (checking versions and rejecting on conflict) or pessimistic locking (blocking until safe).</p> <p>Implementation</p> <ul> <li>Map each command to a corresponding Command Handler</li> <li>Load the relevant model</li> <li>Validate command preconditions against current state</li> <li>Apply the state change and persist it</li> <li>Return success or failure</li> </ul> <p>Example</p> <ul> <li>PlaceOrder: Load the customer model, check available balance, record the order if sufficient funds exist</li> </ul> <p>Resulting Context</p> <ul> <li>Each command is validated against authoritative state</li> <li>Concurrent modifications are either serialized or rejected</li> <li>Integrity is preserved inside the consistency boundary of the model</li> </ul> <p>Consequences</p> Type Description \u2705 Ensures correctness of state changes \u2705 Provides immediate validation against authoritative data \u26a0\ufe0f Does not protect against stale commands outside boundary <p>Related Patterns</p> <ul> <li>Gatekeeper: Filters commands across boundaries before they reach the Command Handler</li> <li>Event Handler: Coordinates asynchronous reactions after command execution</li> </ul>"},{"location":"components/#event-handler","title":"Event Handler","text":"<p>Context</p> <p>In distributed systems, actions often produce consequences beyond the immediate consistency boundary. Commands executed in one place generate events, domain facts describing what has happened (for example OrderPlaced or ProductArchived). These facts must often be communicated to other parts of the system which may run on different nodes, services or geographies.</p> <p>Because of this distribution, events cannot always be reacted to synchronously. Network latency, partitions and independent scaling force asynchronous handling. This distribution naturally results in eventual consistency between components.</p> <p>Problem</p> <p>How can we ensure that different parts of the system react appropriately to domain events, even though event delivery is asynchronous and queried state may be stale?</p> <p>Forces</p> Force Description Asynchrony Event delivery has no global ordering guarantee Resilience Failures must not result in lost reactions Idempotency Events may be delivered more than once Context Reacting to an event often requires additional information gathered through models Staleness Queried state may lag due to eventual consistency <p>Solution</p> <p>Use Event Handlers to subscribe to domain events. An Event Handler:</p> <ul> <li>Consumes events as facts</li> <li>Optionally queries additional models to enrich its decision</li> <li>Triggers side effects such as updating models, starting workflows, notifying external systems or compensating for conflicts</li> </ul> <p>Like Gatekeepers, Event Handlers operate with the best available view of state and must tolerate stale data. The key difference is when they act:</p> <ul> <li>Gatekeeper: Validates commands before execution</li> <li>Event Handler: Reacts to events after execution</li> </ul> <p>Together, they form a two-stage defense: Gatekeepers prevent many invalid actions upfront while Event Handlers reconcile and extend the system after facts have been established.</p> <p>Implementation</p> <ul> <li>Listen for domain events emitted by authoritative Command Handlers</li> <li>Handle events idempotently (safe to reprocess)</li> <li>Query models to gather supporting context</li> <li>Trigger appropriate side effects such as updating models, notifying services, initiating workflows or performing compensations</li> <li>Use retries and dead-letter queues for robustness</li> </ul> <p>Example</p> <ul> <li>OrderPlaced event: The handler queries the customer model to decide whether to trigger a loyalty program workflow</li> <li>ProductArchived event: The handler queries the order model to find all active orders that still reference the product and cancels them</li> <li>Race condition resolution: If an order was accepted for a product being removed, the Event Handler compensates by canceling the order and notifying the customer</li> </ul> <p>Resulting Context</p> <ul> <li>Domain events are propagated as immutable facts</li> <li>Other parts of the system respond to those facts asynchronously</li> <li>Business rules are enforced over time, using the best available state at the moment of reaction</li> </ul> <p>Consequences</p> Type Description \u2705 Ensures system-wide reactions to authoritative facts \u2705 Supports long-running workflows and cross-boundary coordination \u26a0\ufe0f Event Handlers may base decisions on stale query results \u26a0\ufe0f Complexity of retries, ordering and compensation must be managed carefully <p>Related Patterns</p> <ul> <li>Command Handler: Produces events as authoritative facts</li> <li>Gatekeeper: Prevents many invalid commands upfront, reducing cleanup burden</li> <li>Saga: A higher-level orchestration built on Event Handlers</li> </ul>"},{"location":"components/#query-handler","title":"Query Handler","text":"<p>Context</p> <p>Many systems need to respond to read-only requests (queries) that expect up-to-date or near real time data. These requests typically target a single view or model specifically built for reading.</p> <p>Problem</p> <p>How can the system efficiently serve read requests without introducing inconsistency or performance bottlenecks by relying on write-side or multi-view models?</p> <p>Forces</p> Force Description Freshness Queries require reasonably current data but strict consistency may be relaxed Performance Reads must be fast, joins across many sources slow responses Scalability The view must handle large volumes of queries efficiently Isolation Query workload should not interfere with write workload <p>Solution</p> <p>Introduce a Query Handler that serves queries from a single, read-optimized view. The view is maintained asynchronously and may lag slightly behind the write model but guarantees fast, consistent access within its scope.</p> <p>Implementation</p> <ul> <li>Maintain read-optimized views (materialized views, read replicas, denormalized tables)</li> <li>Apply caching where appropriate</li> <li>Ensure each query retrieves data from one view only</li> <li>Optionally expose version or timestamp metadata to indicate view staleness</li> </ul> <p>Example</p> <ul> <li>A product catalog service responds to <code>GET /products/{id}</code> by reading from a denormalized product view</li> <li>A customer profile API retrieves the latest known preferences from a projection without joining multiple sources</li> </ul> <p>Resulting Context</p> <ul> <li>Reads are fast and predictable</li> <li>Query logic remains simple and well scoped</li> <li>Some staleness is tolerated in exchange for scalability and performance</li> </ul> <p>Consequences</p> Type Description \u2705 Efficient and scalable reads \u2705 Clear separation of read vs write responsibilities \u26a0\ufe0f View staleness can cause users to see outdated information <p>Related Patterns</p> <ul> <li>Data Processor: Maintains derived models or multi-source projections</li> <li>Event Handler: Updates the single view consumed by the Query Handler</li> </ul>"},{"location":"components/#data-processor","title":"Data Processor","text":"<p>Context</p> <p>Systems often require derived models or aggregated projections that combine data from multiple sources.</p> <p>Problem</p> <p>How can derived models be kept correct and reasonably fresh when they depend on multiple evolving sources with different consistency guarantees?</p> <p>Forces</p> Force Description Freshness vs Cost More timely updates increase complexity and resource usage Fault tolerance Failures in any input stream must not corrupt derived models Consistency boundaries Data may span multiple bounded contexts with different guarantees Maintainability Transformation logic should be testable and evolvable <p>Solution</p> <p>Introduce a Data Processor that:</p> <ul> <li>Performs more than one query against two or more sources or views</li> <li>Joins or merges the results and computes derived fields as needed</li> <li>Returns the combined result to the caller or writes it to a derived model</li> </ul> <p>Implementation</p> <ul> <li>Issue queries in parallel where possible</li> <li>Use timeouts and fallbacks for slower or unavailable sources</li> <li>Prefer a consistent read point when available to reduce skew</li> <li>Keep joins explicit and bounded, avoid unbounded fan out</li> <li>Cache small reference data that is reused across queries</li> <li>Handle partial failures deterministically and surface what is stale</li> <li>Persist the combined result only when a reusable derived view is needed</li> </ul> <p>Example</p> <ul> <li>A \u201cCustomer 360\u201d view merges data from billing, orders and support systems</li> <li>A recommendation list built from user activity and product data</li> </ul> <p>Resulting Context</p> <ul> <li>Applications can issue one logical request instead of managing multiple queries themselves</li> <li>Cross-source data can be combined into a single, coherent response</li> <li>Query complexity is centralized in the Data Processor, not spread across clients</li> <li>Overall system remains simpler because consumers depend on one result rather than many sources</li> </ul> <p>Consequences</p> Type Description \u2705 Enables complex domain-specific models and analytics \u2705 Offloads heavy queries from transactional stores \u26a0\ufe0f Additional latency from multiple round trips \u26a0\ufe0f Inputs may have different freshness which can surface as inconsistencies <p>Related Patterns</p> <ul> <li>Query Handler: Reads from derived views maintained by the Data Processor</li> </ul>"},{"location":"components/#hotspots-and-descriptions","title":"Hotspots and Descriptions","text":""},{"location":"components/#consistency-boundaries","title":"Consistency Boundaries","text":"<p>Interestingly, even if this is done as a last step in the  Scalable Modeling, this often requires business-driven  decisions. For instance, while financial transactions demand strict consistency, less critical processes like  reporting can tolerate delays.</p> <p>Dynamic Consistency Boundaries (DCB) is an emerging term, and as we leave defining the  consistency boundaries as a last step we make Scalable Modeling compatible with DCBs.</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#credits","title":"Credits","text":"<p>The following persons have had a lot of influence on what this repository describes:</p>"},{"location":"credits/#alberto-brandolini","title":"Alberto Brandolini","text":"<p>Creator of Event Storming, a collaborative workshop technique used to explore and model  complex business processes through domain events. His approach helps teams rapidly gain insights into business  domains by focusing on key events that drive processes.</p>"},{"location":"credits/#eric-evans","title":"Eric Evans","text":"<p>Known for pioneering Domain-Driven Design (DDD), a software development philosophy that emphasizes  aligning the software model closely with the business domain. His work focuses on creating a shared understanding  between technical teams and domain experts to ensure the software reflects real-world complexity.</p>"},{"location":"credits/#gregory-young","title":"Gregory Young","text":"<p>Renowned for developing and promoting Command Query Responsibility Segregation (CQRS) and  Event Sourcing. His work centers on separating read and write operations in systems, improving scalability,  and using event sourcing to maintain the history of all changes in a system, offering resilience and insights  into past system states.</p>"},{"location":"credits/#robert-c-martin","title":"Robert C. Martin","text":"<p>Author of Clean Architecture and a key figure in the promotion of software craftsmanship. His  principles focus on building flexible, maintainable, and scalable systems by adhering to the separation of concerns  and reducing dependencies between different layers of the system. Martin advocates for architecture that allows  software to evolve over time, ensuring it remains easy to understand, extend, and refactor, even as requirements  change. His work is centered on creating systems that prioritize independence from frameworks, databases, and UI,  ensuring longevity and adaptability in software design.</p>"},{"location":"credits/#the-trigger-that-led-to-this","title":"The Trigger that Led to This","text":"<p>The trigger that led to the creation of this page came from a LinkedIn post by Allard Buijze. The post was about aggregates and their necessity. I studied the post and ended up watching Sara Pellegrini's and Milan  Savic's talk: The Aggregate is dead. Long live the Aggregate!. After overcoming my cognitive dissonance, I needed to try out the new ideas by drawing them with Excalidraw, which led to new ideas that I have collected in this repository.</p> <p>Thanks for triggering the ideas!</p>"},{"location":"events/","title":"Events","text":""},{"location":"events/#why-events","title":"Why Events?","text":"<p>Events are central to modeling because they reflect real things that happen in a business domain. They are factual, meaningful and naturally align with how business people think.</p>"},{"location":"events/#1-events-represent-business-truth","title":"1. Events Represent Business Truth","text":"<p>Events are things that have happened in the domain (e.g. <code>OrderPlaced</code>, <code>PaymentReceived</code>, <code>InvoiceGenerated</code>). They are past-tense, factual and undeniable truths from the business perspective.</p> <ul> <li>\u2705 \"OrderPlaced\" happened  </li> <li>\u2705 \"EmailSent\" happened  </li> <li>\u274c \"ShouldSendEmail\" is not a fact, it\u2019s an intent  </li> </ul> <p>Events are also immutable: once they occur, they cannot be changed. This immutability makes them a reliable record of what actually happened, supporting auditing, debugging and replayable workflows.</p> <p>Focusing on what has happened aligns everyone with concrete, observable business behavior.</p>"},{"location":"events/#2-events-are-language-everyone-understands","title":"2. Events Are Language Everyone Understands","text":"<p>Everyone in an organization understands business events. They talk about them naturally in meetings:</p> <p>\u201cA customer placed an order\u201d \u201cThe payment failed\u201d \u201cA reminder was sent\u201d</p> <p>This makes events a shared language between tech and non-tech people, critical for closing the communication gap.</p>"},{"location":"events/#3-events-drive-system-behavior","title":"3. Events Drive System Behavior","text":"<p>In event-driven systems, events trigger workflows, reactions and decisions. They\u2019re not just outcomes, they're inputs for other parts of the system.</p> <p>For example:</p> <ul> <li>Event: <code>OrderPlaced</code> </li> <li>Reaction: Send confirmation email, update inventory, start shipping process</li> </ul>"},{"location":"events/#4-events-help-map-the-real-workflow","title":"4. Events Help Map the Real Workflow","text":"<p>By laying out events on a timeline, you can see the actual flow of a business process: what happens first, what follows and what causes what.</p> <p>This helps:</p> <ul> <li>Discover hidden logic  </li> <li>Spot race conditions  </li> <li>Understand dependencies  </li> <li>Reveal time-based behaviors</li> <li>Find knowledge gaps</li> </ul>"},{"location":"events/#5-events-are-stable-over-time","title":"5. Events Are Stable Over Time","text":"<p>Requirements and processes change but past events remain valid. Designing systems around events often leads to more maintainable and resilient systems because:</p> <ul> <li>Events don\u2019t change often (e.g. <code>OrderPlaced</code> is always meaningful)  </li> <li>New behaviors can react to existing events without breaking existing functionality</li> </ul>"},{"location":"events/#6-events-help-discover-domain-insights","title":"6. Events Help Discover Domain Insights","text":"<p>When people start talking in terms of events, domain knowledge surfaces more easily. Participants begin to ask:</p> <ul> <li>What caused this event?  </li> <li>What should happen next?  </li> <li>Who or what handled it?  </li> <li>Is this event always followed by another?</li> </ul> <p>This leads to better understanding of cause-effect relationships and underlying business logic.</p>"},{"location":"events/#7-events-contribute-to-scalability","title":"7. Events Contribute to Scalability","text":"<p>Events decouple producers and consumers, allowing systems to scale independently and asynchronously. This pattern supports high-throughput architectures where:</p> <ul> <li>Services can process events at their own pace.</li> <li>Workloads can be distributed across consumers.</li> <li>New services can subscribe to existing events without modifying the core system.</li> </ul> <p>Because events are immutable, they can be safely stored, replicated and replayed across distributed systems without coordination or risk of data inconsistency. Immutability makes it possible to:</p> <ul> <li>Rebuild system state by replaying events.</li> <li>Scale horizontally by sharing event streams.</li> <li>Audit and debug with confidence in historical accuracy.</li> </ul> <p>This makes event-based systems easier to scale, more reliable under load and more resilient to failure.</p>"},{"location":"implementing-logic/","title":"Implementing Logic","text":""},{"location":"implementing-logic/#implementing-logic","title":"Implementing Logic","text":"<p>Now that we\u2019ve learned about the various \"sticky notes\" that help model the system, the next question is: where should  we actually implement the business logic? Let\u2019s start by framing the problem. At a high level, systems react to  triggers and produce effects. A system has a state that follows the rules and structure defined by its  model. Scalable systems consist of multiple states and models, as in distributed environments, there cannot be a  single state.</p> <p>Info</p> <p>In this section I decided to use a notation that is a mix of functional programming and mathematical notation, as I wanted to keep the content of this document technology- and programming-language-agnostic.</p> <p>Here, function f represents the logic that connects the Trigger and State to the Effect.</p> \\[ f(\\text{Trigger}, \\text{State}) \\to \\text{Effect} \\] <p>...but not all logic is business/domain logic, so we need to drill deeper.</p>"},{"location":"implementing-logic/#triggers","title":"Triggers","text":"\\[ \\text{Trigger} \\in \\begin{cases} \\text{Command} \\\\ \\text{Event} \\\\ \\text{Query} \\end{cases} \\] <p>Triggers (messages) in the system can be classified as:</p> <ul> <li>Commands: Requests to change the system state.</li> <li>Events: Facts that describe changes in the system state.</li> <li>Queries: Requests to retrieve the system state.</li> </ul>"},{"location":"implementing-logic/#state-and-model","title":"State and Model","text":"<p>A system has a state that follows the rules and structure defined by its model. Scalable systems consist of  multiple states and models, as in distributed environments, there cannot be a single state.</p> <p>Sometimes, the current state of the (sub)system is required by the function that is implementing logic (e.g. for command  validation), and sometimes it is not (e.g. during event processing).</p> \\[ \\text{State} \\in \\{\\emptyset, \\text{state}\\} \\] <ul> <li>The model defines the structure of the state.</li> <li>The state can only evolve along the pathways permitted by the model.</li> </ul>"},{"location":"implementing-logic/#effects","title":"Effects","text":"\\[ \\text{Effect} \\in \\begin{cases} \\text{CommandDispatch} \\\\ \\text{EventEmission} \\\\ \\text{QueryInvocation} \\\\  \\text{StateUpdate} \\\\ \\text{Reply} \\end{cases} \\] <p>The system can produce the following effects:</p> <ul> <li>Command dispatch: Issuing a command to the system.</li> <li>Event emission: Publishing one or more events.</li> <li>Query invocation: Executing one or more queries on the system.</li> <li>State update: Modifying the current system state.</li> <li>Reply: Sending a response to the trigger source.</li> </ul> <p>Effects can lead to chain reactions, meaning one effect may produce additional effects:</p> \\[ \\text{Effect} \\to \\{\\text{Effect}\\}^* \\]"},{"location":"implementing-logic/#businessdomain-logic","title":"Business/Domain Logic","text":"<p>Returning to the business logic: it can be implemented by using three types of policies:  Command Handlers, Event Handlers &amp; Gatekeepers - all functions. Other parts of the system primarily deal  with wiring, integration or restructuring data.</p> <p>Ideally, business logic is implemented within the command model, but due to the need for distribution and managing cognitive load, not all business logic can remain in the command models alone.</p> <p> </p> Policy Trigger Responsibility Validation and state mutation Choreography between subsystems Validation over consistency boundaries State Dependency Direct access to current state Access to eventually consistent state Access to eventually consistent state Timing Synchronous Asynchronous Synchronous Examples \"Remove product from order if not the last product in order.\" \"Send a notification after order approval.\" \"Update stock after order approval.\" \"Add product to order if product exists.\""},{"location":"implementing-logic/#command-handler","title":"Command Handler","text":"<p>This is the core of the system where the \"magic\" happens. Commands are validated and applied against the command model,  causing the state to evolve.</p> \\[ f(\\text{Command}, \\text{State}) \\to \\text{Effect} \\] \\[ \\text{Effect} \\in \\begin{cases} \\text{Reply} \\\\ \\text{EventEmission} \\to \\text{Reply} \\\\ \\text{StateUpdate} \\to \\text{Reply} \\end{cases} \\] <p>Function returns:</p> <ul> <li>Only Reply in case of invalid command.</li> <li>EventEmission of one to many events in case command is approved and event sourcing is used.</li> <li>StateUpdate in case command is approved and state storage is used.</li> </ul>"},{"location":"implementing-logic/#event-handler","title":"Event Handler","text":"<p>To ensure future scalability and manage the sustainable cognitive load of implementation teams, large models need to be  decomposed into smaller ones. Interactions between these models are defined by event handlers,  which also contain business/domain logic. Event handlers typically implement simple \"if-this-then-that\" rules.</p> \\[ f(\\text{Event}) \\to \\text{Effect} \\] \\[ \\text{Effect} \\in \\begin{cases} \\text{CommandDispatch} \\\\ \\text{EventEmission} \\\\ \\text{QueryInvocation} \\to \\begin{cases} \\text{CommandDispatch} \\\\ \\text{EventEmission} \\end{cases} \\end{cases} \\] <ul> <li>Commands can be dispatched to cause new effects in other places of the service / bounded context.</li> <li>Public Events can be emitted/published for other services / bounded contexts to consume.</li> <li>Queries can be used to enrich the event data before command dispatch or public event emission.</li> </ul>"},{"location":"implementing-logic/#gatekeepers","title":"Gatekeepers","text":"<p>When making large-scale decisions, it is often necessary to consult different parts of the system across consistency  boundaries before executing a command. The term Gatekeeper reflects its intended role, as eventual consistency  introduces risks in its application. A Gatekeeper should be used strictly to verify logical conditions.</p> \\[ f(\\text{Command}) \\to \\text{QueryInvocation} \\to \\text{CommandDispatch} \\] <p>For example, the Gatekeeper ensures the product has been introduced before it can be added to an order. However, if  a product can be removed, there must be a process in place to handle open orders that include the removed product.</p> <p>To ensure data integrity, Event Handlers should be used alongside Gatekeepers, forming a cohesive process that  prevents gaps in the eventually consistent system.</p>"},{"location":"opportunities/","title":"Opportunities","text":""},{"location":"opportunities/#opportunities","title":"Opportunities","text":""},{"location":"opportunities/#the-three-dimensions-to-scalability","title":"The Three Dimensions to Scalability","text":"<p>In this section we are in the context of:</p> <ul> <li>Event-Driven Architecture (EDA)</li> <li>Command Query Separation (CQS)</li> <li>Command Query Responsibility Segregation (CQRS)</li> </ul> <p>If these are not familiar to you, please refer to theory section. </p> <p>Scale Cube</p> <p> </p>"},{"location":"opportunities/#decomposition","title":"Decomposition","text":"<p>Decomposition means creating smaller, independently deployable services that together form a system. This involves identifying clear business boundaries where each service owns its commands, events and read models.</p> <ul> <li>Clear ownership and isolation: Services and their development teams operate independently, reducing coordination and integration bottlenecks.</li> <li>Parallel development: Features can be built in parallel without contention over shared code or data.</li> <li>Tailored scaling: Each service scales based on its own load profile such as a high-write order service versus a low-traffic reporting service.</li> </ul> <p>Decomposition is about slicing systems along domain boundaries to create independently scalable event-driven units.</p>"},{"location":"opportunities/#duplication","title":"Duplication","text":"<p>Duplication in Scalable Modeling context means maintaining multiple read models that subscribe to events from the write model.</p> <ul> <li>Performance: Queries target optimized read models without affecting writes.</li> <li>Resilience: Failures in one projection do not impact others.</li> <li>Recoverability: Lost projections can be rebuilt by replaying events.</li> </ul> <p>Duplication improves responsiveness and throughput by offloading read concerns from the write model.</p>"},{"location":"opportunities/#partition","title":"Partition","text":"<p>Partitioning splits data and processing by a key such as customer ID, region or tenant. Each partition handles its own subset of commands, events and queries.</p> <ul> <li>Horizontal scaling: Load is distributed across partitions.</li> <li>Performance: Related operations stay local, reducing cross-partition traffic.</li> <li>Resilience: Failures in one partition do not affect the whole system.</li> <li>Operational flexibility: Shards can be deployed, upgraded or scaled independently.</li> </ul> <p>Partitioning allows each segment of the system to operate and evolve in isolation while maintaining global consistency through event streams.</p>"},{"location":"resilience/","title":"Resilience & Responsiveness","text":"<p>Success demands systems that are both resilient to failures and responsive at all times. Both of these qualities depend on scalability, especially in systems expected to grow.</p> <ul> <li>Resilience is the system\u2019s ability to recover from failures and continue operating ideally without data loss or service downtime.</li> <li>Responsiveness is about how quickly a system reacts to user actions or requests, maintaining consistent performance under varying load. While availability is part of this, it's not the whole story. A system can be \u201cavailable\u201d but still frustratingly slow. We\u2019ve all stared at spinners. What we want isn\u2019t just availability but responsiveness.</li> </ul> <p>A non-scalable system might perform well under low load but as usage grows it can quickly become unresponsive or prone to failure, directly undermining both resilience and responsiveness.</p> <ul> <li>Scalability supports resilience by allowing systems to redistribute load, isolate failures and add resources to minimize the risk of total failure.</li> <li>Scalability supports responsiveness because it enables elasticity<sup>1</sup>. When traffic spikes, an elastic system can spin up additional application servers, database replicas and other resources. This prevents latency bottlenecks and helps maintain fast consistent response times even under pressure.</li> </ul> <p>With Scalable Modeling, models enable systems that are resilient and responsive by design.</p> <ol> <li> <p>Elasticity is the runtime expression of scalability. It\u2019s the system\u2019s ability to automatically scale up or down in response to current demand.\u00a0\u21a9</p> </li> </ol>"},{"location":"scalability/","title":"Scalability","text":""},{"location":"scalability/#success-requires-scalability","title":"Success Requires Scalability","text":"<p>Successful systems tend to become more successful over time, so they need to scale.</p> <p>Building a scalable foundation allows businesses to adapt to increasing demands and capitalize on opportunities without  being limited by technical constraints. As these influential leaders have noted, scalability is not an afterthought; it  is integral to achieve sustainable success.</p> <p>Quote</p> <p>\"The faster you scale, the more wealth you create.\"</p> <p>Reid Hoffman (Co-founder of LinkedIn)</p> <p>Quote</p> <p>\"In order to win, you must be able to scale exponentially.\"</p> <p>Marc Andreessen (Founder of Andreessen Horowitz)</p> <p>Quote</p> <p>\"The most scalable businesses in the world are software businesses.\"</p> <p>Bill Gates (Founder of Microsoft)</p> <p>Without a scalable design from day one, even the best ideas can be slowed down by bottlenecks and inefficiencies as they grow. Designing with scalability in mind ensures that as demand increases, systems can grow exponentially to meet those demands without sacrificing performance or creating technical debt.</p> <p>Success isn\u2019t just about growing fast, it\u2019s about building the right foundation from the start, so that growth  becomes an advantage rather than a challenge.</p>"},{"location":"shift-left/","title":"Shift Left","text":""},{"location":"shift-left/#software-engineering-flow","title":"Software Engineering Flow","text":"<p>Software is ultimately a model, a conceptual solution that, while invisible, solves real-world challenges.  In software engineering, three aspects are critical:</p> <ol> <li>Understanding: WHY the software is needed and by who (understanding the purpose and the problem    it should address).</li> <li>Designing: WHAT is the conceptual model for the solution.</li> <li>Developing: HOW the solution is implemented.</li> </ol> <p> </p> <p>Scalable Modeling serves as an opinionated bridge from WHY to HOW, with a primary focus on the WHAT.</p> <p>Iteration is naturally much cheaper when it is done on the conceptual model rather than on the implementation level.</p>"},{"location":"shift-left/#shift-left","title":"Shift Left","text":"<p>Quote</p> <p>\"There is nothing so useless as doing efficiently that which should not be done at all.\"</p> <p>Peter Drucker</p> <p> </p> <p>Scalable Modeling is a method for shifting left in the software engineering process. It helps crystallize the 'why' by focusing on the 'what,' allowing the creation of a result (the model) that serves as an opinionated bridge to the 'how'.</p>"},{"location":"simo-roikonen/","title":"Author","text":""},{"location":"simo-roikonen/#about-simo-roikonen","title":"About Simo Roikonen","text":"<p> Schedule a Call  LinkedIn  BlueSky</p> <p>Simo is a seasoned software crafter, solution architect, communicator and learner with a deep commitment to building evolvable, long-lasting backends. With over a decade of experience in Domain-Driven Design, Simo excels at transforming complex problems into clear actionable solutions. When systems require scaling and resilience, he brings a proven track record in distributed architectures and scalability, delivering low-latency at any scale.</p> <p>Beyond the technical aspects, Simo understands that successful software development and high development velocity thrive in a balanced sociotechnical environment. He values collaboration and brings stakeholders together to ensure smooth progress whether it's a modernization effort, greenfield project or eliminating bottlenecks in existing systems. Simo is adept at crafting solutions that meet both technical and organizational needs, ensuring systems that are robust, scalable and future-ready.</p>"},{"location":"simo-roikonen/#system-modernization","title":"System Modernization","text":"<p>Simo has extensive experience in modernizing complex large-scale systems. This process involves not only experimenting, organizing and communicating but also leveraging modern technologies and architectures. Modernization in Simo\u2019s view is a sociotechnical exercise where he has consistently served as a hands-on technical leader.</p>"},{"location":"simo-roikonen/#removing-bottlenecks","title":"Removing Bottlenecks","text":"<p>Bottlenecks should only exist for a purpose. While unwanted bottlenecks can often be addressed through optimization, he recognizes that more robust solutions like horizontal scalability and distribution are frequently necessary to achieve sustainable growth and performance.</p>"},{"location":"simo-roikonen/#domain-driven-design","title":"Domain-Driven Design","text":"<p>In complex domains achieving both high quality and development velocity depends on creating a shared language that everyone from developers to stakeholders can understand. This alignment is the secret sauce of success as building complex systems is at its core a process of communication.</p>"},{"location":"start-from-events/","title":"Start From Events","text":""},{"location":"start-from-events/#start-modeling-from-events","title":"Start Modeling From Events","text":"<p>To design reliable scalable systems, we need to start from temporal thinking (the flow of time and how  things evolve) and gradually move into spatial thinking (the arrangement of things). In essence, we design  spatial systems to handle temporal matters: events.</p> <p>Services are rooted in space but act in time: At any given moment, a service's location is tied to a physical or  virtual environment (e.g. a server, container or cluster). Over time, services evolve as they process events, make  decisions and produce outputs.</p> <p>Events are rooted in time but act in space: Events are fixed to the moment they are created, carrying an  immutable snapshot of information. Often, events are related to space in addition to time, but due to their  immutability, their replicated 'echoes' move between services.</p> <p></p><p></p> <p>So, instead of focusing too much on the space between services, consider the flow of events and how services evolve over time.</p> <p>The immutability of events contributes significantly to scalability, particularly in event-driven architectures. Additionally, events play a central role in uncovering domain insights and fostering a shared language. Thus, we adopt an event-centric approach.</p>"},{"location":"start-from-events/#event-centrism","title":"Event Centrism","text":"<p>In Event Centrism, everything we experience is either an event or a trace of one. Reality is not made up of static objects but a continuous flow of occurrences where everything from a falling leaf to a mountain is part of an ongoing process. Even seemingly permanent things are temporary outcomes of past events, always subject to change.</p> <p>Our lives are driven by events. Every thought, action and emotion is triggered by something and memories are a collection of past events that define who we are. Traces of past events like an old building or a weathered book remind us of what once occurred, continuing to shape the present.</p> <p>Events can also be potential, waiting to happen, or hidden, unfolding beyond our perception like biological processes or distant cosmic phenomena. Every event is part of a cause-and-effect continuum, influencing future occurrences. Time, in this view, is meaningful only as the medium through which events unfold.</p> <p>Even the self is an ongoing event, constantly shaped by experiences and interactions. In Event Centrism, everything in life is fluid, dynamic and interconnected, emphasizing that our world and our identities are in constant motion, driven by the events we experience.</p> <p>Event Centrism is not an absolute truth but rather one way to understand the world, a very useful way to model systems.</p>"},{"location":"theory/","title":"Theory","text":""},{"location":"theory/#short-prerequisite-theory","title":"Short Prerequisite Theory","text":""},{"location":"theory/#event-driven-architecture-eda","title":"Event-Driven Architecture (EDA)","text":"<p>Event-Driven Architecture (EDA) is a design pattern where systems react to events in near real-time. Components communicate by producing, detecting, and responding to events, enabling asynchronous processing and loose coupling between services, which allows for more scalable and resilient systems.</p> <p> </p>"},{"location":"theory/#commandquery-separation-cqs","title":"Command\u2013Query Separation (CQS)","text":"<p>Command\u2013Query Separation (CQS) is a design principle introduced by Bertrand Meyer during his work on the Eiffel programming language. It defines a strict division between operations that mutate system state (commands) and operations that retrieve information (queries). Each method should be either a command or a query but not both. This separation improves program clarity by preventing hidden side-effects in queries and it supports testing and reasoning by preserving functional purity in information retrieval.</p>"},{"location":"theory/#command-query-responsibility-segregation-cqrs","title":"Command Query Responsibility Segregation (CQRS)","text":"<p>CQRS is a pattern built on top of CQS that separates the responsibilities of updating data (commands) and reading data (queries). By dividing these operations, CQRS improves performance, scalability and security, enabling more efficient handling of complex or high-demand systems.</p> <p> </p> <p>Scalable Modeling does not go into purism in CQRS -  in Scalable Modeling queries can (when well justified) also query  command models for improved consistency where it does not jeopardize the scalability. Command model may later fork to  query model(s), and commands can also return simple data like sequence number of the produced events.</p>"},{"location":"theory/#vertical-horizontal-scalability","title":"Vertical &amp; Horizontal Scalability","text":"<p> Universal Scalability Law, Wikipedia</p> <p>Limiting contention is the key for higher scalability.</p>"},{"location":"theory/#event-sourcing","title":"Event Sourcing","text":""},{"location":"velocity-quality/","title":"Development Velocity & Quality","text":"<p>Domain knowledge is the most underrated key to high development velocity and quality.</p> <p>Quote</p> <p>\"It's developer (mis)understanding that's released in production, not the experts' knowledge.\"</p> <p>Alberto Brandolini</p> <p>Without a proper understanding of the domain, it's impossible to implement a conceptual model that accurately  reflects it. Effective collaboration with domain experts is essential to bridge this gap. Events play a central  role in uncovering domain insights and fostering a shared language. Events are the backbone of business reality: they are observable, language-neutral, stable and behavior-driving elements that make it easier to understand, design and evolve complex systems. Additionally, the immutability of events contributes significantly to scalability, particularly in event-driven architectures. That\u2019s why Scalable Modeling puts them front and center. </p> <p> </p> <ul> <li> <p>Quote</p> <p>\"A complex system that works is invariably found to have evolved from a simple system that worked.\"</p> <p>John Gall</p> </li> <li> <p>Tip</p> <p>Design flaws in the simple system tend to compound and lead to exponentially increasing complexity in the complex system.</p> </li> <li> <p>Quote</p> <p>\"Doing the wrong thing right is not nearly as good as doing the right thing wrong.\"</p> <p>Russel L. Ackoff</p> </li> <li> <p>Tip</p> <p>Without a proper understanding of the domain, it's easy to prioritize technical correctness over solving the actual problem.</p> </li> <li> <p>Quote</p> <p>\"Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.\"</p> <p>Melvin E. Conway</p> </li> <li> <p>Tip</p> <p>Conceptual models derived from the domain often lead to software structures that should mirror the communication structures within the organization.</p> </li> <li> <p>Quote</p> <p>\"Civilization advances by extending the number of important operations which we can perform without thinking of them.\"</p> <p>Alfred North Whitehead</p> </li> <li> <p>Tip</p> <p>When we focus solely on implementing conceptual models from the domain and minimize concerns about technical details, we achieve the highest velocity in problem-solving.</p> <p>It\u2019s like how modern engineers don\u2019t need to worry about manually managing memory in high-level languages or how mathematicians use symbolic computation tools instead of solving everything by hand. Each layer of abstraction frees us to think bigger and move faster.</p> </li> </ul>"},{"location":"when/","title":"When?","text":""},{"location":"when/#change-log","title":"Change Log","text":"Version Date Changes Made 0.1 2024-10-11 Components of Distributed Systems Modeling (EDA &amp; CQRS) 1.0 2024-11-01 Published: Scalable Modeling \u2013 An Event-centric Approach 1.1 2025-01-24 New section added: Implementing Logic 1.2 2025-04-17 New sub-section added: Resilience and Responsiveness 1.3 2025-05-30 New look and structure 1.4 2025-06-19 Why Events?, Updated CEQS, \"Avoiding Loops to Prevent Time Travel\" 1.5 2025-08-15 Improved front page and a new blog 1.6 2025-09-14 Improved descriptions for patterns: Gatekeeper, Command Handler, Event Handler, Query Handler &amp; Data Processor. Published a related blog post: The Integrity Chain: Guardians of Distributed Systems"},{"location":"when/#related","title":"Related","text":"Time Description 2025-08 Master's Thesis, Jose O Hidalgo: Command Event Query Separation: A Framework for Modeling Scalable Services 2024-11 Webinar recording: Software engineering for the future: Fast, scalable and built to last"},{"location":"when/#schedule-a-call","title":"Schedule a Call","text":"<p> Schedule a Call</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/","title":"Beyond the Stack: How Organizational Structure Shapes Software Architecture","text":""},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/#beyond-the-stack-how-organizational-structure-shapes-software-architecture","title":"Beyond the Stack: How Organizational Structure Shapes Software Architecture","text":"<p>The work of a software architect is highly technical, and that is also how the role is commonly perceived. However, what often gets overlooked is the sociological aspect of this discipline. No matter how well the architecture is described, the success of putting it into practice ultimately depends on the collaboration and understanding among the people involved.</p>"},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/#software-architecture-reflects-social-dispersion","title":"Software architecture reflects social dispersion","text":"<p>It\u2019s common sense that if we restrict communication channels between teams building a solution, the resulting software architecture is likely to mirror this fragmentation.</p> <p></p> <p>Restricting communication can lead to a push towards siloing</p> <p>Let\u2019s also consider a bit more complicated scenario where different teams are responsible for various layers of the software stack. Layers could include, for example, frontend, backend and database. Each team, focusing on its specialized layer, may unintentionally create a system that lacks cohesion and seamless integration. Technological boundaries are just one example among many other boundaries like business domains, availability, or location.</p> <p>To spice up the scenario, let\u2019s add a second boundary in addition to technology: location. Physical separation, be it due to geographical distances or departmental divisions, can also leave its imprint on the architecture. If your development group is split across two different locations, with local subgroups communicating face-to-face daily, expect the architecture to reflect this physical dispersion.</p> <p></p> <p>When speaking the same (technological or other) ubiquitous language, the communication is much more efficient. Same thing when communicating face to face - it just is more effortless than communication via technical communication channels.</p>"},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/#communication-follows-the-path-of-least-resistance","title":"Communication follows the path of least resistance","text":"<p>Communication tends to naturally follow the path of least resistance, favoring the most effortless channels.</p> <p></p> <p>Natural communication flows</p> <p>In the example organization shown above, it makes sense that the resulting system structure would naturally start to resemble the picture below due to the least resistance principle.</p> <p></p>"},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/#underlying-forces-at-play","title":"Underlying forces at play","text":"<p>As we consider reshaping the architecture, it\u2019s crucial to acknowledge and understand the strong underlying forces that may attempt to revert it to its original form.</p> <p></p> <p>Underlying forces trying to fragment the architectural attempts</p> <p>To address these challenges, we need to make thoughtful changes in how our organization communicates. This involves adjusting the way teams interact, tackling the issues also raised by Conway\u2019s Law, as outlined by Melvin Conway in his 1968 article \u201cHow Do Committees Invent?\u201d.</p>"},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/#conways-law","title":"Conway's Law","text":"<p>Melvin E. Conway, How Do Committees Invent?</p> <p>Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.</p> <p>Conway\u2019s Law challenges the traditional notion of architecture as a purely technical discipline. It emphasizes the social fabric within an organization, asserting that the patterns of communication, collaboration, and cooperation are integral to shaping the software architecture.</p> <p></p> <p>Conclusions from the article \u201cHow Do Committees Invent?\u201d by Melvin Conway</p> <p>While Conway\u2019s Law is a conceptual framework rather than a law in the scientific sense, there is empirical evidence and anecdotal support that suggests its validity in various contexts. Several case studies and observations in the field of software development and organizational behavior provide evidence that aligns with Conway\u2019s Law.</p> <p>Understanding Conway\u2019s Law provides a roadmap for intentional and positive architectural design and raises the question: Should you design your organization with the awareness that how your teams are structured will inevitably shape the software they create? Answer is, yes.</p>"},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/#guiding-force-for-positive-change","title":"Guiding force for positive change","text":"<p>The exciting prospect lies in transforming Conway\u2019s Law from a constraint into an asset through the implementation of the Inverse Conway Maneuver. This proactive strategy empowers teams to deliberately shape communication and collaboration structures within an organization, leading to a positive impact on and enhancement of the resulting software architecture. Instead of simply adapting to existing communication patterns, teams take charge by intentionally designing the organizational structure to align with their desired outcomes in software development.</p> <p>Implementing the following principles can help ensure that your organization\u2019s structure fosters a conducive environment for positive software development outcomes:</p> <ol> <li>Cross-functional Collaboration: Encourage collaboration across different disciplines. Break down the barriers that lead to siloed thinking and foster a culture of shared goals.</li> <li>Flexible Team Structures: Design teams with flexibility in mind. Adapt to the evolving needs of the project rather than sticking rigidly to predefined roles.</li> <li>Open Communication Channels: Emphasize open and transparent communication. This not only includes formal channels but also informal ones, encouraging spontaneous exchanges of ideas and information.</li> <li>Shared Vision and Goals: Ensure that teams share a common vision and goals. Aligning everyone towards a unified objective helps create a cohesive software architecture that reflects the organization\u2019s overarching mission.</li> </ol> <p>By intentionally incorporating these principles into your organizational structure, you leverage Conway\u2019s Law as a guiding force for positive change. Your software architecture becomes a reflection of a well-aligned and collaborative team, resulting in more robust and effective solutions.</p>"},{"location":"blog/2024/03/12/beyond-the-stack-how-organizational-structure-shapes-software-architecture/#conclusions","title":"Conclusions","text":"<p>As communication follows the path of least resistance and as building a larger scale solution is all about communication it is natural that the architecture starts to resemble the natural communication flows within the organization building it. We can leverage this by encouraging cross-functional collaboration, making team structures flexible, opening communication restrictions and putting effort into sharing vision and goals. The software architecture and communication structures go hand in hand and therefore software architecture is sociotechnical discipline.</p>"},{"location":"blog/2024/10/01/sw-skills-underrated-being-easy-to-work-with/","title":"SW Skills Underrated: Being Easy to Work With","text":""},{"location":"blog/2024/10/01/sw-skills-underrated-being-easy-to-work-with/#sw-skills-underrated-being-easy-to-work-with","title":"SW Skills Underrated: Being Easy to Work With","text":"<p>What are some ways you\u2019ve worked on becoming easy to work with? Asking for a friend\u2026 \ud83d\udc40</p> <p>Let\u2019s face it, some folks are just easy to work with, and it doesn\u2019t always have anything to do with having the same goals or interests. From my experience, those who are easy to work with tend also to be successful in their careers. I believe being easy to work with is essential for success in any field, but it\u2019s especially important in software engineering.</p>"},{"location":"blog/2024/10/01/sw-skills-underrated-being-easy-to-work-with/#why-do-i-believe-being-easy-to-work-with-is-especially-important-in-software-engineering","title":"Why do I believe being easy to work with is especially important in software engineering?","text":"<p>Software is ultimately a model, a conceptual solution that, while invisible, solves real-world challenges. In software engineering, two things matter: the conceptual solution (designing the what) and how it is implemented (developing the how). End users usually care much less about the technical details than about how well the solution solves their problems, so conceptual solution needs to be rock solid. This is where things like Domain-Driven Design, Systems Thinking &amp; Residuality Theory for example, can help.</p> <p></p> <p>Great software design happens through iterative teamwork where people from diverse backgrounds come together to tackle complex, abstract problems and shape this conceptual solution. The challenge isn\u2019t just technical: because of our diverse mental models, people often speak the same language but mean different things. For software success, teams need to create a shared language through conversations that ensure alignment on key terms and ideas. One efficient technique to use here is EventStorming, a collaborative workshop method that helps teams map out complex processes.</p> <p></p> <p>This is where being easy to work with becomes critical. In an industry that often focuses on technical skills, the ability to foster productive, clear, and empathetic communication can be the \ud835\ude33\ud835\ude26\ud835\ude22\ud835\ude2d difference between project success and failure. When you\u2019re easy to work with, you make those conversations productive and create the shared understanding that drives success.</p>"},{"location":"blog/2024/10/01/sw-skills-underrated-being-easy-to-work-with/#heres-how-ive-tried-to-practice-it","title":"Here\u2019s how I\u2019ve tried to practice it:","text":"<ol> <li>Be clear and concise in communication to reduce misunderstandings (you get extra points for adding an agenda to meeting invitations).</li> <li>Listen actively to understand others\u2019 perspectives before jumping to conclusions (you know, instead of nodding while thinking about the next thing you want to say).</li> <li>Stay open to feedback and adjust your approach when needed. Maintain a positive attitude, especially when facing challenges or disagreements (a smile during tough moments goes a long way).</li> <li>Foster trust and empathy by showing genuine care for others\u2019 perspectives and creating a supportive environment. Trust grows when people feel understood and valued, making collaboration smoother and more effective.</li> </ol> <p>I truly believe that being easy to work with is the most underrated skill in the tech-focused software industry, and it just might be the key to your success. So, how do you ensure you\u2019re easy to work with on your team?</p>"},{"location":"blog/2025/01/07/from-crud-to-real-time-analytics-why-business-events-matter/","title":"From CRUD to Real-Time Analytics: Why Business Events Matter","text":""},{"location":"blog/2025/01/07/from-crud-to-real-time-analytics-why-business-events-matter/#from-crud-to-real-time-analytics-why-business-events-matter","title":"From CRUD to Real-Time Analytics: Why Business Events Matter","text":"<p>Many operational systems (e.g. SaaS platforms and transactional systems) are built around CRUD operations and batch processing, but these approaches often fall short when businesses demand real-time insights.</p> <p>A common intermediate step is Change Data Capture (CDC), which reflects changes at the database level in near-real time. However, CDC primarily captures raw data changes (e.g., inserts, updates, deletes) and doesn\u2019t provide the context of what those changes mean in the real world. For example, CDC might log an update to a database row, but it doesn\u2019t tell you that the event was actually an \u201cOrder Shipped\u201d.</p> <p></p> <p>This is where business events come in. Business events are high-quality, domain-specific data: they describe meaningful occurrences like \u201cPayment Processed\u201d or \u201cCustomer Registered\u201d. Unlike raw data changes, these events provide the context and structure needed to power real-time analytics and unlock the full potential of AI and machine learning. These events, often called domain events, form the backbone of event-driven systems.</p>"},{"location":"blog/2025/01/07/from-crud-to-real-time-analytics-why-business-events-matter/#businessdomain-events-in-practice","title":"Business/Domain Events in Practice","text":"<p>For reliably generating, publishing and consuming these domain events, patterns like the transactional outbox, subscription, and event sourcing play crucial roles:</p> <ul> <li> <p>Transactional outbox ensures that events are published consistently as part of the same database transaction that writes the underlying data, providing robustness even during failures. </p> </li> <li> <p>Subscription pattern enables systems to listen for and react to specific events in near real-time, enabling event-driven workflows and processes. </p> </li> <li> <p>Event sourcing goes further by making events the source of truth, storing all changes as an immutable sequence of events \u2014 empowering systems with a full audit history and the ability to reprocess or replay events at any time. </p> </li> </ul> <p>By adopting event-driven architectures and producing event streams, organizations can move beyond traditional paradigms. This approach enables:</p> <p>Timely, actionable insights through real-time analytics. A foundation of rich, contextual data for AI and ML applications. Real-time notifications to trigger actions and inform stakeholders instantly. Better system design with domain-driven thinking at the core.</p> <p>Conclusion: Core domains in modern scalable operational systems should embrace business/domain events over Change Data Capture (CDC). Domain-driven design and event-driven architecture pave the way for creating future-proof systems.</p> <p>Scalable modeling as an event-centric approach provides a strong foundation for building long-lasting operational systems that deliver low latency and enable real-time analytics at any scale.</p>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/","title":"Software\u2019s Real Cost Is Building Wrong Features","text":""},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#softwares-real-cost-is-building-wrong-features","title":"Software\u2019s Real Cost Is Building Wrong Features","text":"<p>Every year companies spend millions building software that looks right in a demo but collects dust in production. The issue is not lazy engineers or indecisive stakeholders. It is a gap in understanding between the people who know the problem and the people who write the code.</p> <p>This perspective draws on both global studies and recent Nordic research to show why teams ship features nobody uses and how to stop it.</p> <p>The result: bloated backlogs, features that miss the mark and a steady drain on budget. An often-cited figure from an early 2000s Standish Group report suggests that around 64% of features in delivered software saw little or no use<sup>1</sup>. More recent large-scale product analytics paint an even starker picture: Pendo\u2019s 2019 Feature Adoption Report, based on usage data from over 600 companies, found that about 80% of features were rarely or never used<sup>2</sup>. While the exact percentage varies between studies, the underlying pattern that many features go unused remains widely observed. If you are funding those features you are paying for waste.</p> <p>The good news is that many of the most expensive misunderstandings can be addressed before the first line of code is written. Coding will still raise new questions but with a shared understanding in place those iterations are faster, cheaper and far less painful.</p>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#why-this-problem-hurts-the-bottom-line","title":"Why This Problem Hurts the Bottom Line","text":"<p>Misunderstood requirements create a chain reaction of cost overruns and missed value.</p> <ul> <li>NASA\u2019s own analysis shows that fixing a requirements defect during design can be 3\u00d7 to 8\u00d7 more expensive than catching it in the requirements phase. In integration and test phases the cost jumps to 21\u00d7 to 78\u00d7, and in extreme cases (when found in production) it can exceed 1 500\u00d7<sup>5</sup></li> <li>Research by Barry Boehm and others has shown that 30\u201350% of development effort is often spent on avoidable rework, much of it caused by misunderstood or incomplete requirements<sup>6</sup></li> <li>In a Nordic study, engineers spent over 16 hours per week in meetings, much of it dealing with misunderstandings that could have been avoided through earlier shared understanding<sup>3</sup></li> <li>A Swedish multi-company study found that weak alignment between requirements work and testing leads to rework, quality defects and delivery delays even when stakeholders believe they have a shared understanding<sup>4</sup></li> </ul> <p>These are not just statistics. They are your budget leaking out of the project one misunderstanding at a time.</p>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#how-the-gap-opens","title":"How the Gap Opens","text":"<p>When a project jumps from Purpose &amp; Problem (Why) straight to Implementation (How), there is no shared bridge between the two.</p> <p>Domain experts focus on why the software is needed and who needs it. Engineers focus on how it will be implemented.</p> <p>Without a shared middle ground, intent is often lost. The result is software that works technically but fails to solve the real problem, leading to expensive rework and wasted features.</p> <p>In the Nordic study, many of those 16 hours per week spent in meetings were used to realign teams after these gaps emerged. Instead of moving work forward, time was spent repairing shared understanding that should have been built before implementation began<sup>3</sup>.</p> <p>The Swedish study showed a similar pattern. Requirements and testing teams often worked from different assumptions, lacked traceability between specifications and verification steps and coordinated too late. This fragmented approach slowed delivery and created duplicate effort<sup>4</sup>.</p>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#closing-the-gap","title":"Closing the Gap","text":"<p>Quote</p> <p>\"There is nothing so useless as doing efficiently that which should not be done at all.\"</p> <p>Peter F. Drucker</p> <p> </p> <p>The missing link is the Conceptual Model (What).</p> <p>This is the shared understanding of how the solution will address the purpose and problem. It is built collaboratively between domain experts, engineers, architects and designers before implementation begins.</p> <p>By making the Conceptual Model explicit, teams ensure:</p> <ul> <li>The purpose is understood</li> <li>The scope is clear</li> <li>The transition from concept to implementation is smooth</li> </ul>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#why-early-alignment-saves-money","title":"Why Early Alignment Saves Money","text":"<p>Iteration cost is low when teams adjust at the Conceptual Model stage. Feedback at this level is fast, inexpensive and easy to act on.</p> <p>Once a project moves into Implementation, changes become far more expensive and slow to deliver.</p> <p>Early alignment does not remove the need for iteration. It ensures that when new questions or discoveries come up during coding they can be addressed faster, with fewer side effects and at a much lower cost.</p> <p>Validating the Purpose &amp; Problem and the Conceptual Model early gives teams:</p> <ul> <li>Cheaper changes</li> <li>Faster learning cycles</li> <li>Fewer costly surprises in delivery</li> </ul>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#tools-that-close-the-gap","title":"Tools That Close the Gap","text":""},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#domain-driven-design-ddd","title":"Domain-Driven Design (DDD)","text":"<p>DDD is a way to embed the business language directly into the design and code.</p> <ul> <li>Ubiquitous Language locks meaning to agreed terms</li> <li>Bounded Contexts prevent rules from bleeding across domains</li> <li>Collaborative modeling ensures experts stay involved until the intent is clear</li> </ul> <p>These practices also address one of the Swedish study\u2019s key findings that closer, earlier collaboration between requirements and testing roles improves alignment and reduces wasted effort<sup>4</sup>.</p>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#event-storming","title":"Event Storming","text":"<p>A fast, visual workshop where engineers, architects, designers and experts map business events together.</p> <ul> <li>Reveals hidden complexity in hours</li> <li>Surfaces misunderstandings before coding begins</li> <li>Creates shared ownership of the solution</li> </ul>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#the-payoff","title":"The Payoff","text":"<p>Addressing the expert\u2013engineer gap is not a nice-to-have. It is a cost-control measure.</p> <p>Teams that invest in collaborative domain exploration:</p> <ul> <li>Deliver features that get used</li> <li>Reduce rework and budget overruns</li> <li>Build systems that align with the real business</li> </ul>"},{"location":"blog/2025/08/08/how-to-stop-paying-for-features-nobody-uses/#final-word","title":"Final Word","text":"<p>Quote</p> <p>\"It's developer (mis)understanding that's released in production, not the experts' knowledge.\"</p> <p>Alberto Brandolini</p> <p>Software is translation. Every mistranslation costs money. DDD and Event Storming will not remove all project risk but they make misunderstandings expensive to ignore and cheap to fix.</p> <p>If you are tired of paying for features nobody uses bring your experts and engineers into the same room before the first sprint. The savings start before the code does.</p> <p>And remember: increasing developers\u2019 domain understanding is necessary, but not sufficient. Sustainable success also depends on an iterative, user-centric approach where real usage feedback shapes the product continuously. Without that loop, even well-understood domains risk delivering features that miss the mark.</p> <ol> <li> <p>Standish Group (2002). CHAOS Report figure cited by Mike Cohn in LinkedIn article. This is an older data point used here as an illustration of the problem, not a current benchmark.\u00a0\u21a9</p> </li> <li> <p>Pendo (2019). Feature Adoption Report. Based on usage data from 615 companies, showing that about 80% of features are rarely or never used. Report PDF \u21a9</p> </li> <li> <p>Stray, V. G., &amp; Moe, N. B. (2020). Understanding Coordination in Global Software Engineering: A Mixed-Methods Study on the Use of Meetings and Slack. arXiv:2007.02328. PDF \u21a9\u21a9</p> </li> <li> <p>Bjarnason, E., Rasmusson, A., Unterkalmsteiner, M., Engstr\u00f6m, E., &amp; Gorschek, T. (2023). Challenges and Practices in Aligning Requirements with Verification and Validation: A Case Study of Six Companies. arXiv:2307.12489. PDF \u21a9\u21a9\u21a9</p> </li> <li> <p>NASA (2010). Cost of Fixing Defects. Based on analysis of NASA software projects and multiple independent studies. Relative cost multipliers: 3\u00d7\u20138\u00d7 in design, 7\u00d7\u201316\u00d7 in build, 21\u00d7\u201378\u00d7 in integration/test, and up to 1 500\u00d7 in extreme post-deployment cases. PDF \u21a9</p> </li> <li> <p>Boehm, B., &amp; Papaccio, P. N. (1988). Understanding and Controlling Software Costs. IEEE Transactions on Software Engineering, 14(10), 1462\u20131477. doi:10.1109/32.6191 \u21a9</p> </li> </ol>"},{"location":"blog/2025/09/14/integrity-chain/","title":"The Integrity Chain: Guardians of Distributed Systems","text":""},{"location":"blog/2025/09/14/integrity-chain/#the-integrity-chain-guardians-of-distributed-systems","title":"The Integrity Chain: Guardians of Distributed Systems","text":"<p>Distributed systems cannot escape their fundamental limits:</p> <ul> <li>Communication across nodes, services or geographies is never instantaneous</li> <li>Network latency, partitions and the speed of light guarantee that eventual consistency is the default state</li> </ul> <p>Yet systems must still process requests, enforce business rules and maintain integrity. To cope with these realities, I use a set of recurring patterns in Scalable Modeling that form the foundation for growth-ready scalable systems.</p> <p>I call them the Three Guardians, and together they form the Integrity Chain:</p> <ul> <li>Gatekeeper: the front-line validator that filters commands across consistency boundaries before they reach execution</li> <li>Command Handler: the authoritative validator and executor of state changes inside a single consistency boundary</li> <li>Event Handler: the asynchronous reactor that makes sure all parts of the system catch up after domain facts are published</li> </ul> <p>The chain works as follows:</p> <ol> <li>A command is checked by a Gatekeeper across consistency boundaries</li> <li>If accepted, it is passed to a Command Handler, which validates it synchronously within its own consistency boundary and either executes it or rejects it</li> <li>The Command Handler produces events as facts when state changes occur</li> <li>Event Handlers consume these events and drive reactions across the system</li> </ol> <p> </p> <p>Note</p> <p>In addition to the Three Guardians, Scalable Modeling also describes the Query Handler and the Data Processor. A Query Handler serves read requests by consulting a single view. A Data Processor, on the other hand, combines data from multiple sources or views to maintain derived models. These roles are important but relatively straightforward, so I have not explored them in detail in this post.</p>"},{"location":"blog/2025/09/14/integrity-chain/#example-ordering-and-archiving-a-product","title":"Example: Ordering and Archiving a Product","text":"<p>Consider a system where customers can order products, but products can also be archived (removed from sale):</p> <ul> <li>A customer issues a command to Order Product X</li> <li>The Gatekeeper checks that Product X exists and forwards the command</li> <li>The Command Handler for the order validates the customer account and records the order if valid</li> <li>The Event Handler later reacts to the OrderPlaced event and updates projections</li> </ul> <p>At the same time, an administrator issues a command to Archive Product X:</p> <ul> <li>The Gatekeeper for product archiving checks for open orders, but due to distribution it may see stale state and allow the archive request to pass</li> <li>The Command Handler archives Product X inside its consistency boundary and emits ProductArchived</li> <li>The Event Handler consumes this event, queries for open orders of Product X and issues compensating actions such as canceling those orders and refunding customers. It waits long enough for the open orders view to catch up so it reflects all orders for Product X after the product was archived.</li> </ul> <p>This demonstrates how the Integrity Chain works:</p> <ul> <li>Gatekeeper prevents many invalid commands but cannot guarantee global freshness</li> <li>Command Handler enforces invariants locally and emits authoritative events</li> <li>Event Handler detects cross-boundary conflicts and reconciles asynchronously</li> </ul>"},{"location":"blog/2025/09/14/integrity-chain/#compensating-actions-as-first-class-features","title":"Compensating Actions as First-Class Features","text":"<p>In distributed systems compensating actions are not merely technical cleanups. They are first-class business features and just as important as the original actions that triggered the need for correction.</p> <p>It is rarely enough to simply delete or undo an operation. In complex domains such as logistics or finance values and states are constantly changing. An order may affect billing, a shipment may alter routing, an invoice may trigger tax reports. If a mistake occurs after one of these actions a dedicated correction process must be triggered. These processes must be explicitly modeled as part of the business domain.</p> <p>Examples include:</p> <ul> <li>Billing and payments: A correction flow issues refunds or credit notes rather than silently rolling back the invoice</li> <li>Logistics: A compensating flow reroutes trucks, updates manifests or notifies partners</li> <li>Regulation: A correction flow files a new report rather than erasing the old one</li> </ul> <p>These compensation and correction flows handle the inevitable gaps between feasibility checks and actual execution in distributed systems. They ensure not only technical consistency but also real-world accountability especially in domains where financial or regulatory stakeholders are involved. Ignoring them leads to messy downstream edits and fragile workarounds.</p> <p>In the Integrity Chain Event Handlers are the natural home for modeling such flows since they react asynchronously to established facts and can drive corrective action across boundaries.</p>"},{"location":"blog/2025/09/14/integrity-chain/#tradeoffs-in-handling-the-archive-order-race","title":"Tradeoffs in Handling the Archive-Order Race","text":"<p>When a product is archived at the same time as new orders are placed, the system must reconcile the conflict. There are several ways to do this, each with different tradeoffs:</p> <ul> <li>Rely on views and compensate later: Archive first, then let an Event Handler query an eventually consistent view of open orders. Once the view has caught up, compensating actions cancel or refund invalid orders. This keeps product and order flows loosely coupled, but reconciliation is delayed and customers may briefly see invalid orders.</li> </ul> <p> </p> <ul> <li>Compensate immediately: When a product is archived, there is a short window where new orders may still slip in. If an order attempts to register to a product that has already been archived, the product rejects the registration. When the Event Handler sees this rejection, it issues a compensating action such as canceling the order.</li> </ul> <p> </p> <p>No single option is universally correct. The choice depends on the domain:</p> <ul> <li>Finance may favor immediate compensation to protect against invalid transactions</li> <li>E-commerce may accept delayed reconciliation for looser coupling and higher throughput</li> <li>Logistics may mix strategies, blocking for some operations while reconciling asynchronously for others</li> </ul> <p>The key is to recognize that compensation, consistency and coupling are all levers. Each domain must strike its own balance.</p>"},{"location":"blog/2025/09/14/integrity-chain/#why-this-matters","title":"Why This Matters","text":"<p>In a globally distributed system, models such as products, customers and orders exist in multiple places. Their read copies may lag behind one another. The Integrity Chain embraces this reality:</p> <p> </p> <ul> <li>Prevention at the edge with Gatekeepers</li> <li>Enforcement within consistency boundaries via Command Handlers</li> <li>Reconciliation across the system through Event Handlers</li> </ul> <p>The result is integrity without requiring impossible global synchrony.</p>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2025/#2025","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2024/#2024","title":"2024","text":""}]}